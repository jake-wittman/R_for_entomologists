[
["index.html", "R For Entomologists 1 Introduction", " R For Entomologists Jake Wittman 2019-02-01 1 Introduction Figure 1.1: Some entomologists, ready to learn R! "],
["organizing-your-work-and-your-code.html", "2 Organizing Your Work and Your Code 2.1 Style guides 2.2 Organizing your work", " 2 Organizing Your Work and Your Code It can be tempting when writing code to be lazy and disorganized. Resist that temptation! Future you will thank you. To help you write more organized code, I’ll demonstrate some examples of good and bad code here. I’ll also provide some tips and tricks that aren’t immediately obvious, and I’ll also introduce how to use R projects to help organize not only your code, but also your files. 2.1 Style guides The first step to writing organized code is to be consistent and the best way to be consistent is to use a style guide. Style guides are used by large organizations where many people may be working on the same project(s) to make sure their code is consistent. Consistent coding allows people to work more easily with other’s code. It can also help you write clearer code for yourself. Here are a few examples: Google’s R style guide Hadley Wickham’s R style guide Someone else’s R style guide As an R beginner, you won’t understand everything discussed in these style guides so they should be a resource you reference as your R skills grow to see if there’s anything you’ve missed. Pick any style guide that you like best and don’t feel the need to follow every single element of the style guide, just make sure you’re consistent and deviate in the same way within a single code file. I won’t spend time going through the details of these style guides but I do want to hilight a few style suggestions that I think are the most important and that you should always follow to make your code more organized and readable. 2.1.1 Spaces Use them! Please! Nothing raises my blood pressure more than when I see code like the following bad example: # Bad = no spaces ggplot(data,aes(x=x_variable,y=_yvariable))+geom_point(aes(colour=site)) # Good = spaces ggplot(data, aes(x = x_variable, y = y_variable)) + geom_point(aes(colour = site)) The first example is so hard to read! WouldyouwanttoreadthisdocumentifIwroteeverythinglikethis? I bet you wouldn’t. Use spaces. Check out one of the style guides to see when you should use spaces. 2.1.2 Long lines of code You should avoid writing a line of code that is longer than 80 characters. There are several reasons for this: Per Hadley Wickham, 80 characters per line fits on a printed page. If your code is longer than 80 characters, you may be trying to do too much at once, like nesting 3 or more functions within one another. 80 characters serves as a good benchmark to keep your code simple. Long lines of code may require sideways screen scrolling, which is annoying. Imagine trying to read a book written so you had to read the first line of every page, then the second line of every page, and so on. Sometimes code within a single function may require more than 80 characters. Spreading this code over multiple lines rather than containing it in one line enhances readability. How do you know if your code goes over 80 characters? Rstudio has a neat feature you can turn on that puts a little bar in your script window showing you where 80 characters is. To turn on this feature, go to the “Tools” dropdown menu and click “Global Options”. From there, click the “Code” section on the left. Then click on the “Display” tab and check the “Show margin” box and set the “margin column” to 80. The spacing example from above provides an example of spreading a long line of code out over multiple lines. # Bad = this time there are spaces, but the code is too long (just barely) ggplot(data, aes(x = x_variable, y = y_variable)) + geom_point(aes(colour = site)) # Good = multiple lines ggplot(data, aes(x = x_variable, y = y_variable)) + geom_point(aes(colour = site)) How do you know where to split lines of code? Split your code among lines so it reads in a uniform way and at least tries to follow a pattern. Keep in mind that when splitting up long lines of code, indenting is your friend. Use indents to make your code line up in ways that are sensible and make it easier to read. Here are a few examples, it’s not important you understand what the code is doing but just pay attention to the patterns (or lack thereof) of dividing up the lines of code. # Bad = no consistent pattern for splitting code between lines, also goes over # 80 characters on occasion. ggplot(data=dat2016, aes(m_total_path)) + geom_histogram(fill=&quot;white&quot;, colour=&quot;black&quot;) + facet_grid(treat_id ~ .) + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + ggtitle(&quot;Total Path Distance&quot;) + labs(x=&quot;Total Path Distance (m)&quot;, y=&quot;# of Larvae&quot;) # Good = Consistent splitting pattern by starting a new line after each +. Also # starting a new line after each comma in the theme() function to keep each line # under 80 characters ggplot(data = dat2016, aes(m_total_path)) + geom_histogram(fill = &quot;white&quot;, colour = &quot;black&quot;) + facet_grid(treat_id ~ .) + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + ggtitle(&quot;Total Path Distance&quot;) + labs(x = &quot;Total Path Distance (m)&quot;, y = &quot;# of Larvae&quot;) # Bad = no consistency, too many nested functions, too long mean_avg_dist2016 &lt;- as.data.frame(as.list(aggregate(m_total_path ~ treat_id, data=dat2016_movers, FUN = function(x) c(mean = mean(x), n = length(x), se = sd(x)/sqrt(length(x)))))) # Better = consistent line splitting but too many functions nested inside one # another. Putting closing parenthesis on different lines can help # compartmentalize code mean_avg_dist2016 &lt;- as.data.frame( as.list( aggregate(m_total_path ~ treat_id, data = dat2016_movers, FUN = function(x) c(mean = mean(x), n = length(x), se = sd(x) / sqrt(length(x) ) ) ) ) ) # Best = Consistent line splitting without nesting too many functions enhances # readability. # In the first function aggregate, we give each argument it&#39;s own line. # When specify the custom function to use (FUN = ...), we split each of those # functions onto their own line. Close paranthesis mark the end of functions aggregate_data &lt;- aggregate(m_total_path ~ treat_id, data = dat2016_movers, FUN = function(x) c(mean = mean(x), n = length(x), se = sd(x) / sqrt(length(x)) ) ) # Then we can take what we produced above and use it below, in a readable form. mean_avg_dist2016 &lt;- as.data.frame(as.list(aggregate_data)) In the last example, it made sense for us to make our code more readable by both spreading the code over more vertical space AND adding an intermediate step where we saved the output of one function and then used that output in another. This is what I was referring to above when I said if a line of code is over 80 characters, you might be trying to do too much in that line. The pipe operator, %&gt;% which is covered elsewhere in this book, is really helpful in preventing this scenario from occurring. There are a lot of smaller details to consider that are mentioned in a style guide, like conventions for naming objects and files and such, but we won’t get into these here. In this section we took a look at some of the nitty-gritty aspect of code writing but for the next few sections, we’re going to zoom out above the code level and talk more generally organizing your files utilizing R projects. 2.2 Organizing your work 2.2.1 RStudio Projects Rstudio provides yet another useful feature to help you organize your files and code in neat self-contained folders, called “R Projects”. From the Rstudio website, “RStudio projects make it straightforward to divide your work into multiple contexts, each with their own working directory, workspace, history, and source documents.” I generally make a separate RStudio project for each work project I’m working on. For example, my Master’s thesis had two chapters based on two different sets of experiments that I did. Each of those chapters had their own folder on my harddrive with an RStudio project file in it, which allowed me to easily keep all my data, code, figures, and writing in one location. RStudio projects are especially useful for easily accessing data in code and saving any outputs from your code, because it automatically sets your working directory for you. You can create a project by going to the File dropdown menu and selecting “New Project”. You can create a project along with a new directory (aka folder) or you can put the project file into an existing folder. For these tutorials, I set up a designated folder to hold all the associated files, here’s an image of what that directory looks like in Windows Explorer: Figure 2.1: An example of a file directory for an R project. The second to last file in that image “R_for_entomoloists.Rproj” with the little blue cube is the R Project file. I can open that file which immediately loads an R session and sets my working directory to the folder containing the R project. This makes it relatively painless to load in any other files like code, data, or others without having to remember long file paths. Let’s compare how you would read the file “example_buprestid_data.csv” into R without using an R project or a working directory, without using an R project but setting the working directory, and using an R project. (Note: this is all done on a Windows machine, so file paths may look different if you’re using a different operating system.) # Load the example csv file into R without using an R project and without first # setting the working directory. read.csv(&quot;C:/Users/wittm094/Google Drive/school_work/grad_school/mini_projects/R_for_entomologists/data/example_buprestid_data.csv&quot;) # Set the working directory first to the directory with all the files and # relevant subfolders and then read the csv file into R setwd(&quot;C:/Users/wittm094/Google Drive/school_work/grad_school/mini_projects/R_for_entomologists&quot;) read.csv(&quot;data/example_buprestid_data.csv&quot;) # If I use an R project instead and start R by opening the project file, this is # all the code I need read.csv(&quot;data/example_buprestid_data.csv&quot;) Take a moment to create an R project file in a folder for one of your projects. Using an R project to help organize our work ends up saving us a line of code, since we don’t have to specify a working directory and it means we don’t have to memorize or find long file directories. The best part of R projects, though, is that it makes it so much easier to share our code! If you send someone the directory containing your R project and all the relevant files, all they have to do is download that directory, open the project file, and R takes care of setting the working directory to be whatever it is on their computer. The other person doesn’t need to to go through and change any directory paths, they can open your code and (assuming your code is functional) run it with no problems. 2.2.2 Organizing your RStudio Project folder So, now that you have your RStudio project folder set up, how should you organize your files within it to help you stay organized? I generally have one folder for each of the following things: data, R code scripts, manuscript/thesis chapter drafts associated with the project, and figures produced in R for the projects. There might be other folders too, like a “images” folder for pictures from the experiment or field sites. Here’s an image of one such directory: Figure 2.2: An example of a file directory for an R project. 2.2.3 Splitting up your code When you first begin writing code, it can be difficult to come up with a coherent system for organizing your code within a script file and to know how many script files you should use. When I first started, my default was to write incredibly long scripts that loaded the data, cleaned the data, analyzed the data, and visualized the data and not necessarily with any clear flow to the script. It was nearly impossible for me to figure out what I had done or remember where I had done it. These days, I like to have one R script for cleaning my data and saving the output as “cleaned_data.csv” and one script for analyzing my data and producing figures. Depending on the number of analyses and figures being produced, that last file could reasonably be split into two. Within a script, I use Rstudio’s “Insert section” feature to help organize these files (ctrl/cmd + shift + r). This command will insert text into your R script that breaks it up into sections which you can jump between using the menu at the bottom of the script screen. Here’s an example of what I mean (ignore the fact that I didn’t follow the 80 character rule. This script was written before I started following that rule.): Figure 2.3: An example of a file directory for an R project. The menu I have pulled up at the bottom is a list of all the code sections I inserted in bold. If you write custom functions, it also allows me to jump to where those functions were written. "],
["introduction-to-data-cleaning-and-manipulation.html", "3 Introduction to Data Cleaning and Manipulation 3.1 Background required 3.2 Let’s get started! 3.3 The pipe 3.4 Pipe examples 3.5 Chaining multiple functions together with the pipe 3.6 dplyr Verbs 3.7 Modifying data with case_when() 3.8 Answers to practice questions", " 3 Introduction to Data Cleaning and Manipulation 3.1 Background required This document assumes you are comfortable with installing and loading packages, reading data into R as a data.frame, assigning values to objects, and using basic functions like mean() and sum(). Before we can start, we’ll need to make sure you have the tidyverse package installed. Run the code below to install the package and load it (don’t worry about understanding the code if you don’t, that’s not the point of this tutorial). if (!require(tidyverse)) install.packages(&quot;tidyverse&quot;) library(tidyverse) 3.2 Let’s get started! R is great for statistical analysis if your data are in the right format, but what do you do if you don’t have your data formatted properly to perform say, an ANOVA or a linear regression? You could make an Excel spreadsheet with multiple worksheets, each with a different format of your data. But this may take anyway from hours to days depending on the complexity of your data and the forms you need your data. Thankfully, with R and the tidyverse package you can speed up your data manipulation and cleaning significantly. This document and activity will walk you through some of the most useful tidyverse functions, show you how I’ve used them (or would have, if I’d known about them at the time) in the past, and demonstrate how to make your code more legible. There will also be some opportunities at the end of the document for you to practice what I’m demonstrating. While you’re reading through this document, pay attention to how I’ve written the code. I use a slightly modified version of the Google style guide, so you can use my code as an example of one possible style. 3.3 The pipe The pipe will be the first tool in your new R toolbox to help you write human readable code. The pipe operator looks like this %&gt;%, and it may look a little weird and confusing especially to someone new to programming. Before I explain exactly what the pipe means and how it works, I want to draw an analogy between the pipe operator and the assignment operator (&lt;-) while also giving a brief lesson on writing readable code. You should be familiar with the assignment operator. It’s used to tell R that you want to store something (a number, a vector, a string, a data frame, etc.) with a particular name. You might do something like this: x &lt;- 4 You can read this R code as “store 4 in x” or “assign the number 4 to the letter x”. This is a basic application of the assignment operator. Let’s look at a slightly more complicated application. # The set.seed function is used to make sure our &quot;random&quot; results are consistent. # Don&#39;t worry if you don&#39;t understand what this function means set.seed(1) # Randomly sample 10 numbers from the numbers 1 through 10 with replacement # and store those 10 numbers in the object &quot;x&quot; x &lt;- sample(1:10, 10, replace = TRUE) # Let&#39;s see what we put in x x ## [1] 3 4 6 10 3 9 10 7 7 1 # Calculate the mean of all the values in x and assign the mean value of x to # the object &quot;y&quot; y &lt;- mean(x) # Let&#39;s check y to see what the mean of x is y ## [1] 6 In simple (probably overly simple, but that’s okay) language, we randomly picked 10 numbers (using the sample() function) and used the assignment operator to “give” these 10 numbers to x. Then we calculated the mean of these 10 numbers and “gave” those numbers to y. Now, if we wanted we could type x or y into the console in R and return the respective value(s) we “gave” to them. Side note: You can also use = as an assignment operator but you shouldn’t. Most R style guides recommend reserving &lt;- as your assignment operator and using = only within a function to specify arguments for the function. If you’ve worked in R a little before or have some programming background, you may know that you can also nest functions inside one another. Instead of assigning 10 random numbers to x and then taking the mean of x, we could have just nested the sample() function inside the mean function like so: y &lt;- mean(sample(1:10, 10, replace = TRUE) Much like when performing the order of operations in a math equation containing multiple sets of parentheses, R will start with whatever function is nested the furthest inside and then work out. So the code above, in plain English, reads as “First, sample 10 numbers from the numbers 1 through 10 with replacement, then take the mean of those 10 numbers and store that mean value as y”. This English “translation” is an accurate representation of what R is doing when it reads that code. That is to say, R executes the code in the same order I described it in in English. Now, take a moment and consider the plain English reading of the above code and compare that to how the code is actually written. How do you read the English sentence? How do you read the code? The code does not read like an English sentence. When we read in English, we read from left to right. In the R code version, we basically end up reading the code from right to left to figure out what order R is working in. A translation that is more faithful to the way the code is actually written might be: “In the object y, we will store the mean of a sample of 10 random numbers between 1 and 10”. This translation doesn’t reflect the order in which R actually reads through the code though (our first translation more accurately reflects the order R works through your code). This results in a mismatch between our expectations as English readers when we are trying to learn to read R code and understand what is happening. Thankfully, the tidyverse has provided us with an operator (the pipe!) to make how we write code match up with our intuitions. TL;DR: English reads from left to right. When you nest functions in R, you end up needing to read the code more or less from right to left. This does not match our intuitions and can make learning read, write, and understand more difficult. Enter the pipe! The pipe operator allows us to reorganize our code so that it reads more like English. Instead of nesting functions, we can “pipe” the results of one function to another function. Here’s the piped version of the above code. set.seed(1) # First sample 10 numbers with replacement between 1 and 10, then take those # numbers and give them to the mean function to find the mean. sample(1:10, 10, replace = TRUE) %&gt;% mean() ## [1] 6 Now, our code lines up with both our expectations for how it should be read (left to right) and how R will execute the code (and if you compare the answer we got for the mean in both examples, you’ll see they’re the same)! First, R will sample 10 numbers from between 1 and 10, then it will “pipe” those ten numbers to the mean function, which will calculate the mean of those 10 numbers. Let’s look at a few more examples of the pipe in action and then there will be a few problems you can work through to practice using the pipe. Side note: You may be confused about the difference between the assignment operator &lt;- and the pipe %&gt;% because of some of the plain English used above. The assignment operator is used to tell R to associate an object name (the variables x or y above) with something else (in our case, a sample of 10 numbers and a mean, respectively). By using the assignment operator you create a permanent association between the object x and the sample of 10 numbers (at least until you remove x from your environment, or reassign x to some other object). The pipe operator does not create any such association. All the pipe operator does is take an object, or the output from a function, and “sends” it to another function to use. You cannot pipe one object to another object, you’ll get an error. If you want to save the output from a function in a pipe chain, you have to use the assignment operator (I’ll cover this later). 3.4 Pipe examples You’ve been measuring the hind tibia length of 20 Cerceris wasps and you want to know the mean, median, and standard deviation. In the below, we’ll generate some random values for hind tibia length and then use the pipe to get the outputs we want. (The rnorm function is used to generate random values from a normal distribution.) # Get 20 random samples from a normal distribution with mean 12 and standard # deviation 3. hind_tibia_length &lt;- rnorm(n = 20, mean = 12, sd = 3) # Let&#39;s pipe our data to our data summary functions # Mean hind_tibia_length %&gt;% mean() ## [1] 12.53554 # Median hind_tibia_length %&gt;% median() ## [1] 13.59482 # Standard deviation hind_tibia_length %&gt;% sd() ## [1] 2.916807 In our three examples, we’ve piped our data to three different functions to get different summaries. Later, I’ll show you how to more efficiently produce these summary results. Now, what do we do if we want to assign our summary output to an object, like when we assigned y &lt;- mean(x)? The code to do that would look like this: # Save mean output mean_tibia_length &lt;- hind_tibia_length %&gt;% mean() # Check that it matches our output from earlier mean_tibia_length ## [1] 12.53554 # Save median output median_tibia_length &lt;- hind_tibia_length %&gt;% median() # Check that it matches our output from earlier median_tibia_length ## [1] 13.59482 # Save sd output sd_tibia_length &lt;- hind_tibia_length %&gt;% sd() # Check that it matches our output from earlier sd_tibia_length ## [1] 2.916807 This might be confusing at first. Didn’t I just say that we want to try to write code that reads like English and also reflects the order in which R will execute the code? Isn’t storing our output in the object the last thing R would do? Why are we putting that first in our code? We sacrifice a little bit of intuitive readability here to speed up our work flow as we write more lines of code. In my experience, I’ve found that I spend more time referencing the objects I’ve saved some output as (“what did I call that again?”, “where did I calculate that?”, etc.) than re-reading exactly what I did. Think of the assignment operator as a placeholder dividing your code into two separate sides, left of the assignment operator and right of the assignemnt operator. By putting the object I’ve saved something as on the left side, it makes it easier for me to find it again in the code or quickly scan what I’ve written to see my output. The readability of what you did on the right hand side of the assignment operator becomes important when you’re returning to code you wrote a long time ago or are sharing code with someone who is looking at it for the first time. This arrangement strikes a balance between your needs while writing code, and your’s or someone else’s needs when looking at the code later. Side note: The pipe operator %&gt;% can be kind of frustrating to type. Thankfully there’s a keyboard shortcut for it in R Studio! If you’re using a Windows machine use ctrl + shift + m to insert the pipe operator. While we’re at it, there’s a shortcut for the assignment operator &lt;- too! Again, on a Windows machine type alt + -. (Sorry, I don’t know the Mac OS shortcuts. A google search might help?) 3.5 Chaining multiple functions together with the pipe You can use the pipe operator to link multiple functions together, which is often useful when summarizing data. Here’s a brief example. I’ll briefly explain what these functions do if you haven’t seen them before, but we’ll cover them in more depth in a bit. In this example, I’ll show you three methods of achieving the same result to highlight again why pipes are useful or preferred over other methods. The first method will nest multiple functions to avoid saving unneeded intermediate objects while still not using pipes.In the second method, we’ll save every intermediate step as an object on our way to our final goal without using any pipes. The final method will use pipes. In this example, we’re using the iris dataset that is built into R. If you type iris into your console, it’ll print out the dataset. This data has observations on sepal length and width and petal length and width for three different species of irises. This example is a little contrived, but it illustrates my point. Imagine you want to take the iris data set and are interested in only the data on Iris setosa. Furthermore, you don’t care about anything but the sepal length of Iris setosa. And for some reason, you want the data ordered from shortest sepal length to longest sepal length for Iris setosa. Here are three ways you could accomplish this using dplyr verbs that let you filter your data based on certain criteria, select particular columns from your data, and arrange the data according to a certain variable: 3.5.1 Nesting multiple functions nested_sepal_length &lt;- arrange(select(filter(iris, Species == &quot;setosa&quot;), Sepal.Length), Sepal.Length) 3.5.2 Saving every intermediate step without any pipes setosa_iris &lt;- filter(iris, Species == &quot;setosa&quot;) sepal_length &lt;- select(setosa_iris, Sepal.Length) intermediate_sepal_length &lt;- arrange(sepal_length, Sepal.Length) 3.5.3 Using multiple pipes piped_sepal_length &lt;- iris %&gt;% filter(Species == &quot;setosa&quot;) %&gt;% select(Sepal.Length) %&gt;% arrange(Sepal.Length) # Let&#39;s compare our three data sets to see if they&#39;re all the same. This # function will return the value TRUE if the two objects called within are # identical. identical(intermediate_sepal_length, nested_sepal_length) ## [1] TRUE identical(intermediate_sepal_length, piped_sepal_length) ## [1] TRUE identical(nested_sepal_length, piped_sepal_length) ## [1] TRUE Based on the pairwise comparisons of our three data frames, all three methods produced the same object. So which is the best? You’ll probably have guessed that I’ll say the pipe method is the best and you’ll be right. Let’s start by comparing the piped method to our nested function. First, let’s compare the pipes to our nested function method. Earlier we saw an example of nesting one function within another; that example wasn’t that hard to read if we really had to. I find the example at hand with three nested functions, each with their own extra arguments, much harder to decipher. As I mentioned before, with nested functions you have to read in a way that is counter-intuitive to the way we usually read. The pipes eliminate that problem, allowing us to read our code in a more natural manner, reducing our intellectual overhead. Now, let’s compare the piped method to our intemediate steps method. Look at the functions filter, select, and arrange in each of the two examples we’re focusing on. You might notice that in the intermediate steps example, each of those three functions has two arguments: the first is the data frame being used and the second specifies what part of the data frame on which the action should be performed. Why do the functions in the piped example not need to specify what data is being used? The pipe operator essentially takes care of informing the next function what data is being used. Convention for most, but not all, R functions is for the first argument to specify what data is being used. The pipe takes advantage of that fact and takes care of the work of specifying the first argument for you, which saves you some typing time and space. The pipes are also useful because you don’t end up with a lot of intermediate objects that you might not use again. Pipes keep your programming environment clean by eliminating many one-use objects which in turn makes it easier to remember what objects you need for specific tasks. I’ve presented the code in order of what I find least preferred to most preferred. Avoid the temptation to nest functions whenever possible, although sometimes nesting 1 function within another is ok (all rules are meant to be broken, right?) if the two functions aren’t too complex. Also, you’ll find that sometimes it makes sense to break up a pipeline (multiple functions piped together) into smaller pipelines. Don’t feel like you need to construct incredibly long, elaborate pipelines. Do what works best for the problems you are trying to address and what makes your code easiest to read. That’s the pipe! It’s a powerful tool for making more legible code, which will make your life and potential collaborator’s lives easier. You’ll get some practice using the pipe once we’ve covered more of the functions provided by the tidyverse for manipulating data. 3.6 dplyr Verbs dplyr is a package in the tidyverse that provides most of the functions we’ll use when manipulating and cleaning our data. As long as you have the tidyverse package loaded, you’ll have dplyr loaded too. Many of the functions in dplyr and the tidyverse as a whole are named as verbs that describe the action they perform. This is a wonderful design feature as it further reduces intellectual overhead required by you when learning new functions or recalling what function to use. Need to filter your data by some critera? Use the filter() function. Your data frame contains data from different experimental groups that you need separate summaries for? Use the group_by() function and then the summarise() function. Side note: When referencing data in this tutorial, I often refer to it as a “data frame”. A data frame is a special type of object in R that is analagous to a spreadsheet; basically, it’s just an object used to store data in named columns. You may notice that many of the dplyr functions we use return what is called a “tibble”. A “tibble” is just the tidyverse version of a data frame. If you’ve worked with data frames before in R, many of the same operations you would do with a data frame will also work on a tibble. However, if the tibble thing is throwing you off, it’s pretty simple to convert a tibble back to a data frame using as.data.frame() function. # Here imagine we use filter on our data frame named data and save it as an # object called &quot;some_tibble&quot;. Because we used a dplyr verb, the output is a # tibble. some_tibble &lt;- data %&gt;% filter() # Now, use as.data.frame() on some_tibble) and assign it to an object. This # object can have the same name as your tibble or you can rename it to something # new, as in this example. some_data_frame &lt;- as.data.frame(some_tibble) Let’s dive in. For these examples we’ll be using some slightly modified data of Buprestid collection records in the state of Minnesota. The records in this data are all true (thanks Marie!) but I’ve added a few columns of artificial data to help illustrate the usefulness of some of the functions we’ll use. Here are the first 10 rows of the data. # Import our data from the data folder in this project # Because we&#39;re using an R studio project, R automatically sets the working # directory to the folder our R project is stored in, so we don&#39;t have to set # our working directory or type a really long file name. The &quot;.&quot; in the filename # is a shortcut for the name of our working directory. buprestid_data &lt;- read.csv(&quot;./data/example_buprestid_data.csv&quot;) head(buprestid_data, n = 10) ## X scientificname county n recent_collect_date recent_id_date ## 1 1 Acmaeodera acuta aitkin 0 NA NA ## 2 2 Acmaeodera acuta anoka 0 NA NA ## 3 3 Acmaeodera acuta anoka/isanti 0 NA NA ## 4 4 Acmaeodera acuta aonka/isanti 0 NA NA ## 5 5 Acmaeodera acuta becker 0 NA NA ## 6 6 Acmaeodera acuta beltrami 0 NA NA ## 7 7 Acmaeodera acuta benton 0 NA NA ## 8 8 Acmaeodera acuta big stone 0 NA NA ## 9 9 Acmaeodera acuta blue earth 0 NA NA ## 10 10 Acmaeodera acuta brown 0 NA NA ## mass length ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA ## 7 NA NA ## 8 NA NA ## 9 NA NA ## 10 NA NA There are 8 columns in this dataset. The first column, X, appears to be an artifact from the csv file and is just a column for row numbers. There are columns for the scientific name of the beetle, the county, the number of that species caught in that county, the most recent collection date, and the most recent identification date. I’ve added two columns of simulated data: one for the dry mass of the most recent beetle caught and one for the length of the most recent beetle caught. Don’t mistake these columns for real data and try to draw any conclusions from them. They’re just a bunch of randomly generated numbers. 3.6.1 Selecting columns using select() The select function can be used to reduce the number of columns in a data frame if you find your data set has more columns than needed for your current analysis. Let’s see a couple examples. First, lets say I just want the columns for scientific name, county, mass, and length. # Be sure to assign your new data frame to a name that isn&#39;t the same as the one # you&#39;re editing or you&#39;ll overwrite the one you&#39;re working with. mass_length_buprestids &lt;- buprestid_data %&gt;% select(scientificname, mass, length) head(mass_length_buprestids) ## scientificname mass length ## 1 Acmaeodera acuta NA NA ## 2 Acmaeodera acuta NA NA ## 3 Acmaeodera acuta NA NA ## 4 Acmaeodera acuta NA NA ## 5 Acmaeodera acuta NA NA ## 6 Acmaeodera acuta NA NA Now we’ve got a data frame with just the three columns we’re interested in! This works well if you have a lot of columns and you want to reduce your data frame down to just a few. What if you have a lot of columns and only need to remove a few? You can still use select for that! Let’s go back to our original data frame and remove that superfluous X column # Because we won&#39;t need the X column at all in the future, we can overwrite the # object we originally stored our data frame in. buprestid_data &lt;- buprestid_data %&gt;% select(-X) By placing the - operator before the column name “X”, we tell the select function that we want every column except X. You could add more column names with a - before them to remove additional columns. If you have a lot of columns you want to select that are all adjacent to one another, you can use the : operator to save some typing. We can use this to select the columns from scientific name through recent_id_date. first_4_cols_buprestid &lt;- buprestid_data %&gt;% select(scientificname:recent_id_date) head(first_4_cols_buprestid) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera acuta aitkin 0 NA NA ## 2 Acmaeodera acuta anoka 0 NA NA ## 3 Acmaeodera acuta anoka/isanti 0 NA NA ## 4 Acmaeodera acuta aonka/isanti 0 NA NA ## 5 Acmaeodera acuta becker 0 NA NA ## 6 Acmaeodera acuta beltrami 0 NA NA The : operator allowed us to select all the columns between scientific name and recent_id_date without typing any additional column names. As a reminder, this only works if the columns you want to select are adjacent to each other. You can use a combination of the : operator with individual column names if you need to select some columns that are adjacent and some that are not. Reminder: Remember that once you pipe your data to a dplyr function, you don’t need to specify the name of the data frame again. In select() we just wrote the name of the column with no mention of the data frame. You might be used to writing something like buprestid_data$scientificname to reference a specific column in a data set. 3.6.2 Filtering rows using filter() While select() allowed us to pick out certain columns from our data set, filter() will allow us to reduce the number of rows based on particular criteria. For instance, maybe we want to get a data set of just the collection records in Ramsey county in Minnesota. ramsey_co_buprestids &lt;- buprestid_data %&gt;% filter(county == &quot;ramsey&quot;) head(ramsey_co_buprestids) ## scientificname county n recent_collect_date recent_id_date mass ## 1 Acmaeodera acuta ramsey 0 NA NA NA ## 2 Acmaeodera alicia ramsey 0 NA NA NA ## 3 Acmaeodera amplicollis ramsey 0 NA NA NA ## 4 Acmaeodera angelica ramsey 0 NA NA NA ## 5 Acmaeodera bowditchi ramsey 0 NA NA NA ## 6 Acmaeodera connexa ramsey 0 NA NA NA ## length ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA Based on the preview of our data set, we can see that we’ve now only selected the rows that have “ramsey” as the value for county. Filter uses the basic logic functions built into R, so you’ll want to familarize yourself with those. In brief, you can read == as “is equal to”. The filter function in this example is combing through our data and looking for all instances where the value of the county column is equal to “ramsey” and selecting only those rows. You can also use !=, which means “is not equal to”. We could have written filter(county != &quot;ramsey&quot;) to remove all observations from Ramsey county from our data set. (Side note: these are referred to as logical operators). The == and != logical operators are useful when you have categorical data or need a specific value of a numeric variable (for example, you might want mass == 10). You can also use &gt;, &gt;=, &lt;, and &lt;= to get numeric values greater than, greater than or equal to, less than, or less than or equal to, respectively. Maybe we want to filter our data so we remove any observations where no buprestids were observed. positive_buprestid_counts &lt;- buprestid_data %&gt;% filter(n &gt; 0) head(positive_buprestid_counts) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera pulchella anoka 1 1932 1938 ## 2 Acmaeodera pulchella chisago 17 1969 NA ## 3 Acmaeodera pulchella faribault 1 1910 1922 ## 4 Acmaeodera pulchella hennepin 2 1938 1943 ## 5 Acmaeodera pulchella le sueur 1 1922 1928 ## 6 Acmaeodera pulchella morrison 3 1920 1928 ## mass length ## 1 66.81645 66.81645 ## 2 43.66621 43.66621 ## 3 49.24207 49.24207 ## 4 65.25690 65.25690 ## 5 73.63759 73.63759 ## 6 76.53053 76.53053 You can also chain together multiple logical arguments to further reduce a dataset. In this example we’re interested in finding any beetles that we have more than two specimens of from Ramsey county. ramsey_co_positive_buprestids &lt;- buprestid_data %&gt;% filter(n &gt; 2 &amp; county == &quot;ramsey&quot;) head(ramsey_co_positive_buprestids) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera pulchella ramsey 4 NA NA ## 2 Actenodes acornis ramsey 3 2017 2017 ## 3 Agrilus arcuatus ramsey 10 NA NA ## 4 Agrilus bilineatus ramsey 4 2017 2017 ## 5 Agrilus difficilis ramsey 19 2017 2017 ## 6 Agrilus egenus ramsey 3 1952 NA ## mass length ## 1 38.31272 38.31272 ## 2 60.86979 60.86979 ## 3 69.61334 69.61334 ## 4 46.94469 46.94469 ## 5 36.88816 36.88816 ## 6 43.82500 43.82500 The &amp; operator does what you might guess it does: in this use of filter() we’re asking R for only rows that have values of n greater than 0 AND the county is “ramsey”. You can also use the | operator to link two statements. The | operator reads as “or”. (Sometimes | is confusingly referred to as a pipe. In this document I’ll only reference it as |, not pipe, to avoid confusion.) A researcher in the Twin Cities might be interested in beetle records for both Hennepin and Ramsey counties. They could filter the data so: ramsey_hennepin_buprestids &lt;- buprestid_data %&gt;% filter(county == &quot;ramsey&quot; | county == &quot;hennepin&quot;) head(ramsey_hennepin_buprestids) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera acuta hennepin 0 NA NA ## 2 Acmaeodera acuta ramsey 0 NA NA ## 3 Acmaeodera alicia hennepin 0 NA NA ## 4 Acmaeodera alicia ramsey 0 NA NA ## 5 Acmaeodera amplicollis hennepin 0 NA NA ## 6 Acmaeodera amplicollis ramsey 0 NA NA ## mass length ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA This code asks R for only rows that have either “ramsey” or “hennepin” in the county column. You can use the logical operators to chain together complicated logical statements to hone in on exactly the rows you want. 3.6.3 Arranging your data with arrange() arrange() can be used to reorder your data frame. This isn’t something I often use in R, because few functions that I can think of require your data to be arranged in a certain way before using them, but it can be useful if you’re trying to look through your data. It’s also much nicer than trying to sort your data in Excel or another spreadsheet program as there is no danger of accidently sorting some data and not others, resulting in a data catastrophe. Let’s tell R that we want to rearrange our data so it’s sorted by county. # It&#39;s okay to overwrite our object here because the only thing we&#39;re doing is # rearranging our data, not editing it. buprestid_data &lt;- buprestid_data %&gt;% arrange(county) head(buprestid_data) ## scientificname county n recent_collect_date recent_id_date mass ## 1 Acmaeodera acuta aitkin 0 NA NA NA ## 2 Acmaeodera alicia aitkin 0 NA NA NA ## 3 Acmaeodera amplicollis aitkin 0 NA NA NA ## 4 Acmaeodera angelica aitkin 0 NA NA NA ## 5 Acmaeodera bowditchi aitkin 0 NA NA NA ## 6 Acmaeodera connexa aitkin 0 NA NA NA ## length ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA Now our data are sorted alphabetically by county! If you want to reverse the order, you just need to use the desc() function with arrange() (one of a few instances where it’s alright to nest functions! We couldn’t use the pipe here anyway). Let’s sort by reverse alphabetical order of scientific name. buprestid_data &lt;- buprestid_data %&gt;% arrange(desc(scientificname)) head(buprestid_data) ## scientificname county n recent_collect_date recent_id_date mass ## 1 Brachys Floricola aitkin 0 NA NA NA ## 2 Brachys Floricola anoka 0 NA NA NA ## 3 Brachys Floricola anoka/isanti 0 NA NA NA ## 4 Brachys Floricola aonka/isanti 0 NA NA NA ## 5 Brachys Floricola becker 0 NA NA NA ## 6 Brachys Floricola beltrami 0 NA NA NA ## length ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA You can provide additional columns to arrange() if you want to sort by more than one column. Maybe we want to sort first by most recent collection date descending, then by county. buprestid_data &lt;- buprestid_data %&gt;% arrange(desc(recent_collect_date), county) head(buprestid_data) ## scientificname county n recent_collect_date recent_id_date ## 1 Agrilus quadriguttatus chisago 10 2017 2017 ## 2 Agrilus pensus chisago 1 2017 2017 ## 3 Agrilus obsoletoguttatus chisago 12 2017 2017 ## 4 Agrilus liragus chisago 2 2017 NA ## 5 Agrilus granulatus chisago 21 2017 2017 ## 6 Agrilus carpini chisago 4 2017 2017 ## mass length ## 1 51.70299 51.70299 ## 2 50.79876 50.79876 ## 3 77.85798 77.85798 ## 4 77.39962 77.39962 ## 5 44.11903 44.11903 ## 6 78.54273 78.54273 3.6.4 “Mutating” new columns with mutate() This is where we start to have some real fun! The mutate() function allows us to take existing data and derive other variables from it. To create a new variable, you need to supply a name for the variable and then tell mutate() what the new variable will be equal to. For example, in this data let’s say the mass variable is recorded in grams. Maybe we want to convert this to kilograms. For this example, we’ll work with the positive counts data set so we have mass and length records to work with instead of NA values. # We can overwrite our original positive_buprestid_counts object becuase we&#39;re just adding # a new column, not doing anything to existing columns. We could also save it as # a new object if we wanted to. positive_buprestid_counts &lt;- positive_buprestid_counts %&gt;% mutate(mass_kg = mass / 1000) head(positive_buprestid_counts) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera pulchella anoka 1 1932 1938 ## 2 Acmaeodera pulchella chisago 17 1969 NA ## 3 Acmaeodera pulchella faribault 1 1910 1922 ## 4 Acmaeodera pulchella hennepin 2 1938 1943 ## 5 Acmaeodera pulchella le sueur 1 1922 1928 ## 6 Acmaeodera pulchella morrison 3 1920 1928 ## mass length mass_kg ## 1 66.81645 66.81645 0.06681645 ## 2 43.66621 43.66621 0.04366621 ## 3 49.24207 49.24207 0.04924207 ## 4 65.25690 65.25690 0.06525690 ## 5 73.63759 73.63759 0.07363759 ## 6 76.53053 76.53053 0.07653053 You can see we now have our original mass column in grams and a new mass_kg column. (You may need to click the arrow in the display table to see the additional column.) You can create multiple new columns by providing additional arguments to the mutate() function. Let’s say our length variable is recorded in millimeters and lets convert that to centimeters. Let’s also multiply length and mass to get an index variable for “size”. positive_buprestid_counts &lt;- positive_buprestid_counts %&gt;% mutate(length_cm = length / 10, size_index = mass * length) head(positive_buprestid_counts) ## scientificname county n recent_collect_date recent_id_date ## 1 Acmaeodera pulchella anoka 1 1932 1938 ## 2 Acmaeodera pulchella chisago 17 1969 NA ## 3 Acmaeodera pulchella faribault 1 1910 1922 ## 4 Acmaeodera pulchella hennepin 2 1938 1943 ## 5 Acmaeodera pulchella le sueur 1 1922 1928 ## 6 Acmaeodera pulchella morrison 3 1920 1928 ## mass length mass_kg length_cm size_index ## 1 66.81645 66.81645 0.06681645 6.681645 4464.438 ## 2 43.66621 43.66621 0.04366621 4.366621 1906.738 ## 3 49.24207 49.24207 0.04924207 4.924207 2424.781 ## 4 65.25690 65.25690 0.06525690 6.525690 4258.463 ## 5 73.63759 73.63759 0.07363759 7.363759 5422.494 ## 6 76.53053 76.53053 0.07653053 7.653053 5856.923 Now there are two more columns! Mutate makes it very easy to add new columns based on existing data 3.6.5 Summarising data with summarise() We can use summarise() to produce quick and easy summaries of our data. The summarise() function works similarly to mutate() in that you have to provide a name for your summary column and then tell the function how it calculates that value. Let’s summarise our count data from the buprestid data by producing a summary table with mean count, median count, number of counts, standard deviation, and the coefficient of variation (standard deviation / mean, this is another measure of how variable our data is like standard deviation but relative to the mean of our data). buprestid_summary &lt;- buprestid_data %&gt;% # We have to tell the function what variable to use to calculate the summary # variable. In our buprestid_data, the variable n is the count data. summarise(mean_count = mean(n), median_count = median(n), num_observations = n(), stdev_count = sd(n), coef_var = sd(n) / mean(n)) buprestid_summary ## mean_count median_count num_observations stdev_count coef_var ## 1 0.08235392 0 11997 1.210113 14.69406 Now the object buprestid_summary returns a one row table with all of our summary data! We used a new function n() to get this summary data. The n() function is a special dplyr function that doesn’t take any arguments, it automatically knows that you want to use it to count up the number of observations in your data. Becuase we’re summarizing our whole dataset, this is just equal to the number of rows in our data. Sometimes you may run into issues when using summarise if your data contain NA values or you are using functions that require additional arguments beyond just the data for them to work. For example, say we wanted to summarise the mean dry mass and length of our full buprestid data. mass_length_summary &lt;- buprestid_data %&gt;% summarise(mean_mass = mean(mass), mean_length = mean(length)) mass_length_summary ## mean_mass mean_length ## 1 NA NA Hmm, shoot. We get NA values for our means. This is because when there are no records for a beetle in a county, they can’t have a mass or a length so instead there is an NA observation there. The mean function (as well as other functions, like the standard deviation function) don’t know what to do with NA values unless we tell them. To handle these NA values, we have to tell R to remove them with the na.rm = TRUE argument that can be provided to mean(). mass_length_summary &lt;- buprestid_data %&gt;% summarise(mean_mass = mean(mass, na.rm = TRUE), mean_length = mean(length, na.rm = TRUE)) mass_length_summary ## mean_mass mean_length ## 1 56.70475 56.70475 Here you can see we succesfully returned mean values for these two variables. If you’re mutating or summarising data and need to provide additional arguments to the function, you add them on just like you would normally. So summarise() is a great tool for quickly getting summary data, but what if we have different groups in our data we want separate summaries for? Maybe we want to know the mean count for each county in Minnesota. Well, there’s a function for that! 3.6.6 Grouping your data using group_by() The group_by() function can be used to tell R what variable it should use to group your data with and this can be paired with summarise() to produce summaries for each group. Let’s calculate the same summary table as before but this time produce a separate row for each county in the data. county_summary &lt;- buprestid_data %&gt;% group_by(county) %&gt;% summarise(mean_count = mean(n), median_count = median(n), num_observations = n(), stdev_count = sd(n), coef_var = sd(n) / mean(n)) county_summary ## # A tibble: 93 x 6 ## county mean_count median_count num_observations stdev_count coef_var ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 aitkin 0 0 129 0 NaN ## 2 anoka 0.721 0 129 3.82 5.30 ## 3 anoka/isa~ 0.0698 0 129 0.562 8.05 ## 4 aonka/isa~ 0.116 0 129 1.32 11.4 ## 5 becker 0 0 129 0 NaN ## 6 beltrami 0.00775 0 129 0.0880 11.4 ## 7 benton 0 0 129 0 NaN ## 8 big stone 0.0155 0 129 0.176 11.4 ## 9 blue earth 0 0 129 0 NaN ## 10 brown 0 0 129 0 NaN ## # ... with 83 more rows Easy! All we had to do was add one additional line of code. You’ll notice in the coefficient of variation variable we have some NaN values. This is because we had a mean count of 0 in those counties and you can’t divide by 0. If you have a dataset with multiple levels of grouping, you can pass additional arguments to group_by to do hierarchical grouping and produce summaries for all your different levels. We’ll use a different dataset to demonstrate this feature. This dataset contains the results of an experiment comparing the effects of different foliage types and time without food on the movement of gypsy moth caterpillars. The dataset we’re about to load has 6 columns. The id column provides a unique identifier to each caterpillar observation, the food column specifies what food source the caterpillar was raised on (one of three tree species or an artificial diet), and the starve column identifies how long the insects were starved before the experiments occurred (either 0, 24, or 48 hours). These three columns are categorical and used to identify the treatments each insect underwent. The total_distance column tells us how far the caterpillar crawled in centimeters during a 10 minute trial and the stops column records how often the insect stopped moving. There is also another superfluous column, again named X that we’ll remove before we work with the data. In the case of this experiment, we’re interested in summarizing how far each combination of food and starvation time moved and how often they stopped. We’ll need to provide both the food and starve column names to group_by() so it gives us the summaries we want. Let’s calculate the mean and standard error (NOT standard deviation) for each, as well as the number of observations for each combination of treatments. While we’re at it, let’s rearrange our summary table so it’s ordered from smallest mean_total_distance to largest. # Load the data caterpillar_movement &lt;- read.csv(&quot;./data/example_movement_data.csv&quot;) # Summarise the data! caterpillar_movement %&gt;% # Use select to remove the X column select(-X) %&gt;% # Group_by to organize our data for summary group_by(food, starve) %&gt;% summarise(mean_total_distance = mean(total_distance), se_total_distance = sd(total_distance) / n(), mean_stops = mean(stops), se_stops = sd(stops) / n(), count = n()) %&gt;% arrange(mean_total_distance) ## # A tibble: 12 x 7 ## # Groups: food [4] ## food starve mean_total_dist~ se_total_distan~ mean_stops se_stops count ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 diet 0 82.8 3.15 72.2 1.92 20 ## 2 diet 24 107. 4.20 33.6 0.764 20 ## 3 diet 48 185. 5.38 39.5 1.66 21 ## 4 larch 24 188. 4.73 27.8 1.97 20 ## 5 norw~ 48 210. 7.30 50.1 2.86 20 ## 6 larch 48 212. 6.23 32.4 1.80 20 ## 7 norw~ 0 223. 7.66 39.5 0.900 20 ## 8 buro~ 0 259. 8.83 42.6 1.06 21 ## 9 larch 0 282. 7.13 17.2 1.05 20 ## 10 norw~ 24 390. 7.78 14.9 0.912 21 ## 11 buro~ 48 391. 11.5 23.2 1.15 21 ## 12 buro~ 24 432. 10.1 30 1.30 20 And there you have it! In just a few lines of code we’ve written an analysis that is: Reproducible. Anyone can grab this code with this data and get the same results we got. Simple to read. No nested functions, no lines with code running off the screen. Simple to think about. Each function serves a (relatively) clear purpose once you’re familiar with them Simple to modify later. We could add more summary variables or rerun the code with additional data without too much trouble. Built from basic building blocks. The packages in the tidyverse are written with a coherent design philosophy, which allows them to play well with each other and makes your code quite modular. You can use many of these functions in different orders and with additional functions and produce elegant code. 3.6.7 tidyverse Practice problems We’ll use some of the datasets built into R to practice using some of these functions. Look for the data_manipulation_cleaning_ANSWERS file if you get stuck or want to check your answers. If you’re working directly inside this R markdown file, feel free to type the code in the code chunks. Otherwise I recommend making your own R script and writing out your answers there. We’ll start by using the iris data set. This data set comes preloaded so you can access it easily from any R session by just typing iris. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa The iris dataset contains four variables which are measurements of sepal and petal length and width for three different species in the Iris genus. Write code that creates a separate data frame with just the petal length, petal width, and species variables. iris_petals &lt;- iris %&gt;% Now, repeat what you did in question one but for the sepal variables and also arrange the data frame from lowest to highest sepal width. iris_sepals &lt;- iris %&gt;% Create two new variables that represents the ratio of sepal length to sepal width and petal length to petal width, respectively, and add them to the iris data frame. Save this as an object separate from the overall iris dataset as you’ll need it in future questions. iris_ratios &lt;- iris %&gt;% Using the data frame you created in the last problem, provide an overall summary of the data. Use R to find the average for all 6 variables included in this data frame. (I don’t want you to use group_by() yet.) iris_ratios %&gt;% Now, repeat what you did in question 4 but provided species level means for all 6 variables (this will require using group_by()). # I&#39;m not starting this one for you :) But you can do it! 3.7 Modifying data with case_when() The case_when() function is, in my mind, a little bit more of an advanced cleaning tool, which is why I’ve positioned it here at the end of this tutorial. This function is a powerful tool for cleaning data based on a set of conditions or constructing new variables in conjunction with mutate. Let’s return to the buprestid data we’ve been working with to illustrate one example. First, take a look at the first 6 rows of this data set when it’s arranged by scientific name. # First few rows of the buprestid data buprestid_data &lt;- buprestid_data %&gt;% arrange(scientificname) head(buprestid_data) ## scientificname county n recent_collect_date recent_id_date mass ## 1 Acmaeodera acuta aitkin 0 NA NA NA ## 2 Acmaeodera acuta anoka 0 NA NA NA ## 3 Acmaeodera acuta anoka/isanti 0 NA NA NA ## 4 Acmaeodera acuta aonka/isanti 0 NA NA NA ## 5 Acmaeodera acuta becker 0 NA NA NA ## 6 Acmaeodera acuta beltrami 0 NA NA NA ## length ## 1 NA ## 2 NA ## 3 NA ## 4 NA ## 5 NA ## 6 NA # Let&#39;s look at all the unique entries for county in our dataset too to check # for more errors. The unique() function looks at all the values in our data # frame buprestid_data, specifically in the column &quot;county&quot; and returns all # the unique values. unique(buprestid_data$county) ## [1] aitkin anoka anoka/isanti ## [4] aonka/isanti becker beltrami ## [7] benton big stone blue earth ## [10] brown carlton carver ## [13] cass chippewa chisago ## [16] clay clearwater cook ## [19] cottonwood crow wing dakota ## [22] dodge douglas faribault ## [25] fillmore freeborn goodhue ## [28] grant hennepin houston ## [31] hubbard isanti itasca ## [34] itasca park jackson kanabec ## [37] kandiyohi kittson koochiching ## [40] lac qui parle lake lake of the woods ## [43] le sueur lincoln lyon ## [46] mahnomen marshall martin ## [49] mcleod meeker mille lacs ## [52] mille lacs lake morrison mower ## [55] murray nicollet nobles ## [58] norman olmsted otter tail ## [61] pennington pine pipestone ## [64] polk pope ramsey ## [67] red lake redwood renville ## [70] rice rock roseau ## [73] saint anthony park santa rita scott ## [76] sherburne sibley st louis ## [79] stearns steele stevens ## [82] swift todd traverse ## [85] wabasha wadena waseca ## [88] washington watonwan wilkin ## [91] winona wright yellow medicine ## 93 Levels: aitkin anoka anoka/isanti aonka/isanti becker ... yellow medicine Look at the county column. You might notice that we have entries for both “anoka/isanti” and “aonka/isanti” counties. The second case, “aonka/isanti” is a typo - there is no Aonka county in Minnesota. If you look through the data set, you’ll see that this typo is repeated. You could further examine the counties and find that there are entries for “saint anthony park”. That’s not a county, it’s a park in Ramsey county, so we’ll want to fix that too. Your first inclination might be to go into Excel and fix it, but you shouldn’t. If this data is updated in the future and someone makes a similar typo, you will have to once again go into Excel and fix it. Instead, we can write a few lines of code that check for common typos we know might exist in our data and fix them using mutate() and case_when(). # Currently county is a factor, we need to change the variable type to string # so we can work with it. If you try to run the code before changing it to a # string you&#39;ll get an error. This isn&#39;t something you would be expected to know # right away and is the type of knowledge you pick up through trial and error # and lots of google searches. buprestid_data$county &lt;- as.character(buprestid_data$county) # Now let&#39;s fix our typo. buprestid_data &lt;- buprestid_data %&gt;% mutate(county = case_when(county == &quot;aonka/isanti&quot; ~ &quot;anoka/isanti&quot;, county == &quot;saint anthony park&quot; ~ &quot;ramsey&quot;, county == county ~ county )) # Check that our typos are fixed unique(buprestid_data$county) ## [1] &quot;aitkin&quot; &quot;anoka&quot; &quot;anoka/isanti&quot; ## [4] &quot;becker&quot; &quot;beltrami&quot; &quot;benton&quot; ## [7] &quot;big stone&quot; &quot;blue earth&quot; &quot;brown&quot; ## [10] &quot;carlton&quot; &quot;carver&quot; &quot;cass&quot; ## [13] &quot;chippewa&quot; &quot;chisago&quot; &quot;clay&quot; ## [16] &quot;clearwater&quot; &quot;cook&quot; &quot;cottonwood&quot; ## [19] &quot;crow wing&quot; &quot;dakota&quot; &quot;dodge&quot; ## [22] &quot;douglas&quot; &quot;faribault&quot; &quot;fillmore&quot; ## [25] &quot;freeborn&quot; &quot;goodhue&quot; &quot;grant&quot; ## [28] &quot;hennepin&quot; &quot;houston&quot; &quot;hubbard&quot; ## [31] &quot;isanti&quot; &quot;itasca&quot; &quot;itasca park&quot; ## [34] &quot;jackson&quot; &quot;kanabec&quot; &quot;kandiyohi&quot; ## [37] &quot;kittson&quot; &quot;koochiching&quot; &quot;lac qui parle&quot; ## [40] &quot;lake&quot; &quot;lake of the woods&quot; &quot;le sueur&quot; ## [43] &quot;lincoln&quot; &quot;lyon&quot; &quot;mahnomen&quot; ## [46] &quot;marshall&quot; &quot;martin&quot; &quot;mcleod&quot; ## [49] &quot;meeker&quot; &quot;mille lacs&quot; &quot;mille lacs lake&quot; ## [52] &quot;morrison&quot; &quot;mower&quot; &quot;murray&quot; ## [55] &quot;nicollet&quot; &quot;nobles&quot; &quot;norman&quot; ## [58] &quot;olmsted&quot; &quot;otter tail&quot; &quot;pennington&quot; ## [61] &quot;pine&quot; &quot;pipestone&quot; &quot;polk&quot; ## [64] &quot;pope&quot; &quot;ramsey&quot; &quot;red lake&quot; ## [67] &quot;redwood&quot; &quot;renville&quot; &quot;rice&quot; ## [70] &quot;rock&quot; &quot;roseau&quot; &quot;santa rita&quot; ## [73] &quot;scott&quot; &quot;sherburne&quot; &quot;sibley&quot; ## [76] &quot;st louis&quot; &quot;stearns&quot; &quot;steele&quot; ## [79] &quot;stevens&quot; &quot;swift&quot; &quot;todd&quot; ## [82] &quot;traverse&quot; &quot;wabasha&quot; &quot;wadena&quot; ## [85] &quot;waseca&quot; &quot;washington&quot; &quot;watonwan&quot; ## [88] &quot;wilkin&quot; &quot;winona&quot; &quot;wright&quot; ## [91] &quot;yellow medicine&quot; If you look through the list of unique county names, you’ll find that there are no more “aonka” typos or records for “st anthony park”. Let’s unpack how we did that. Using mutate(), we told R that we wanted to make edits to the county variable by putting “county” on the left side of that first = operator in mutate(). We could’ve made a new variable by naming it something other than “county”, but we wanted to fix some errors (aka clean our data), so we kept the name the same. Then we told R that we wanted county to be edited according to certain conditions, provided using case_when(). In side case_when(), we specified that whenever county was equal to the value “aokna/isanti” (county == &quot;aonka/isanti&quot;), we wanted R to change it to “anoka/isanti” using the ~. Unfortunately, ~ is used in different ways in different functions so there isn’t a consistent definition for ~ between functions. In the case of case_when(), the ~ can be read as “change to”. So the first line of our case_when() function could be read as “when county is equal to ‘aonka/isanti’, change county to ‘anoka/isanti’”. The second line of our case_when() function then can be read as “when county is equal to ‘saint anthony park’, change county to ‘ramsey’”. So those two lines take care of our common typos. The last line is needed because there are a lot of cases where county isn’t equal to “aonka/isanti” or “saint anthony park”. R is not intelligent enough to know that once we’ve gone through the two specific cases specified that we want the rest to remain the same, so we have to tell it that by specifying that “when county is equal to [any other value of county than the two we specified previously], keep it as is”. When using case_when() it’s important you specify your cases in order from most specific to most general because R will evaluate the code in the order you provide them. The case_when() function can also be used with numeric variables. If we look at the range of beetle mass present in our data, we’ll see that we have observations of beetle masses between about 30 grams and 80 grams. range(buprestid_data$mass, na.rm = TRUE) ## [1] 30.56638 79.77642 Now, you would never want to take a continuous variable like mass and turn it into a discrete variable like size (“small”, “medium”, “large”) for a statistical analysis because you’d lose information. However, there may be other reasons, say for data visualization, that you might want to categorize the mass variable into discrete categories. We can use case_when() to do this. buprestid_data &lt;- buprestid_data %&gt;% # Make our new &quot;size&quot; variable mutate(size = case_when(mass &gt;= 62 ~ &quot;large&quot;, mass &lt; 62 ~ &quot;medium&quot;, mass &lt; 46 ~ &quot;small&quot;)) %&gt;% # Pipe the results to a few different functions so we can display what I need # to show you the relevant results. select(size, mass, everything()) %&gt;% arrange(desc(n)) head(buprestid_data) ## size mass scientificname county n recent_collect_date ## 1 large 79.77642 Anthaxia quercata crow wing 63 1959 ## 2 large 63.96925 Agrilus planipennis ramsey 52 2015 ## 3 medium 60.13572 Agrilus parvus pipestone 51 1973 ## 4 medium 38.38265 Agrilus cuprescens anoka 40 2004 ## 5 medium 40.46855 Agrilus liragus washington 24 2016 ## 6 medium 44.11903 Agrilus granulatus chisago 21 2017 ## recent_id_date length ## 1 NA 79.77642 ## 2 NA 63.96925 ## 3 NA 60.13572 ## 4 NA 38.38265 ## 5 2017 40.46855 ## 6 2017 44.11903 Hmm, something appears to have gone wrong during this code chunk. Lines 4, 5, and 6 of the above output should all be classified as size “small” based on their mass but they weren’t. That’s because we didn’t go from most specific to most general in our case_when() function. mass &lt; 62 is a more general condition than mass &lt; 46 so we need to reverse the order we wrote our case_when() arguments in. (This also illustrates why it’s always important to check results of any code you run! R won’t catch these kinds of errors for you.) buprestid_data &lt;- buprestid_data %&gt;% # Make our new &quot;size&quot; variable mutate(size = case_when(mass &lt; 46 ~ &quot;small&quot;, mass &lt; 62 ~ &quot;medium&quot;, mass &gt;= 62 ~ &quot;large&quot;)) %&gt;% # Pipe the results to a few different functions so we can display what I need # to show you the relevant results. select(size, mass, everything()) %&gt;% arrange(desc(n)) head(buprestid_data) ## size mass scientificname county n recent_collect_date ## 1 large 79.77642 Anthaxia quercata crow wing 63 1959 ## 2 large 63.96925 Agrilus planipennis ramsey 52 2015 ## 3 medium 60.13572 Agrilus parvus pipestone 51 1973 ## 4 small 38.38265 Agrilus cuprescens anoka 40 2004 ## 5 small 40.46855 Agrilus liragus washington 24 2016 ## 6 small 44.11903 Agrilus granulatus chisago 21 2017 ## recent_id_date length ## 1 NA 79.77642 ## 2 NA 63.96925 ## 3 NA 60.13572 ## 4 NA 38.38265 ## 5 2017 40.46855 ## 6 2017 44.11903 That’s better! Now we’ve classified all our masses into size categories. 3.7.1 case_when() practice problem Here’s a histogram showing the distribution of sepal lengths for all the iris observations in the iris dataset. It looks like the sepal lengths tend to fall between 4 and 8 centimeters. Use case_when() to create a new size_sepal_length variable, similar to the above example. Decide how many categories are appropriate and where to place the breaks between categories. Also, edit the Species variable so instead of just listing the species name, it lists both genus and species (for example, “setosa” would become “Iris setosa”. The genus for each case is “Iris”). Bonus points if you can create the size_sepal_length variable and edit the Species variable within a single use of mutate(). 3.8 Answers to practice questions For each practice question provided, it’s possible more than one way to complete the problem exists. I show only one method for each question. Write code that creates a separate data frame with just the petal length, petal width, and species variables. iris_petals &lt;- iris %&gt;% select(Petal.Length:Species) Now, repeat what you did in question one but for the sepal variables and also arrange the data frame from lowest to highest sepal width. iris_sepals &lt;- iris %&gt;% select(Sepal.Length, Sepal.Width, Species) %&gt;% arrange(Sepal.Width) Create two new variables that represents the ratio of sepal length to sepal width and petal length to petal width, respectively, and add them to the iris data frame. Save this as an object separate from the overall iris dataset as you’ll need it in future questions. iris_ratios &lt;- iris %&gt;% mutate(ratio_sepal = Sepal.Length / Sepal.Width, ratio_petal = Petal.Length / Petal.Width) Using the data frame you created in the last problem, provide an overall summary of the data. Use R to find the average for all 6 variables included in this data frame. (I don’t want you to use group_by() yet.) iris_ratios %&gt;% summarise(mean_sepal_length = mean(Sepal.Length), mean_sepal_width = mean(Sepal.Width), mean_ratio_sepal = mean(ratio_sepal), mean_petal_length = mean(Petal.Length), mean_petal_width = mean(Petal.Width), mean_ratio_petal = mean(ratio_petal)) ## mean_sepal_length mean_sepal_width mean_ratio_sepal mean_petal_length ## 1 5.843333 3.057333 1.953681 3.758 ## mean_petal_width mean_ratio_petal ## 1 1.199333 4.3105 Now, repeat what you did in question 4 but provided species level means for all 6 variables (this will require using group_by()). iris_ratios %&gt;% group_by(Species) %&gt;% summarise(mean_sepal_length = mean(Sepal.Length), mean_sepal_width = mean(Sepal.Width), mean_ratio_sepal = mean(ratio_sepal), mean_petal_length = mean(Petal.Length), mean_petal_width = mean(Petal.Width), mean_ratio_petal = mean(ratio_petal)) Here’s a histogram showing the distribution of sepal lengths for all the iris observations in the iris dataset. It looks like the sepal lengths tend to fall between 4 and 8 centimeters. Use case_when() to create a new size_sepal_length variable, similar to the above example. Decide how many categories are appropriate and where to place the breaks between categories. Also, edit the Species variable so instead of just listing the species name, it lists both genus and species (for example, “setosa” would become “Iris setosa”. The genus for each case is “Iris”). Bonus points if you can create the size_sepal_length variable and edit the Species variable within a single use of mutate(). # Find our unique values for Species unique(iris$Species) ## [1] setosa versicolor virginica ## Levels: setosa versicolor virginica # Mutate new variable and edit Species variable iris %&gt;% mutate(size_sepal_length = case_when(Sepal.Length &lt; 5 ~ &quot;small&quot;, Sepal.Length &lt; 7 ~ &quot;medium&quot;, Sepal.Length &gt;= 7 ~ &quot;large&quot;), Species = case_when(Species == &quot;setosa&quot; ~ &quot;Iris setosa&quot;, Species == &quot;versicolor&quot; ~ &quot;Iris versicolor&quot;, Species == &quot;virginica&quot; ~ &quot;Iris virginica&quot;)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 Iris setosa ## 2 4.9 3.0 1.4 0.2 Iris setosa ## 3 4.7 3.2 1.3 0.2 Iris setosa ## 4 4.6 3.1 1.5 0.2 Iris setosa ## 5 5.0 3.6 1.4 0.2 Iris setosa ## 6 5.4 3.9 1.7 0.4 Iris setosa ## 7 4.6 3.4 1.4 0.3 Iris setosa ## 8 5.0 3.4 1.5 0.2 Iris setosa ## 9 4.4 2.9 1.4 0.2 Iris setosa ## 10 4.9 3.1 1.5 0.1 Iris setosa ## 11 5.4 3.7 1.5 0.2 Iris setosa ## 12 4.8 3.4 1.6 0.2 Iris setosa ## 13 4.8 3.0 1.4 0.1 Iris setosa ## 14 4.3 3.0 1.1 0.1 Iris setosa ## 15 5.8 4.0 1.2 0.2 Iris setosa ## 16 5.7 4.4 1.5 0.4 Iris setosa ## 17 5.4 3.9 1.3 0.4 Iris setosa ## 18 5.1 3.5 1.4 0.3 Iris setosa ## 19 5.7 3.8 1.7 0.3 Iris setosa ## 20 5.1 3.8 1.5 0.3 Iris setosa ## 21 5.4 3.4 1.7 0.2 Iris setosa ## 22 5.1 3.7 1.5 0.4 Iris setosa ## 23 4.6 3.6 1.0 0.2 Iris setosa ## 24 5.1 3.3 1.7 0.5 Iris setosa ## 25 4.8 3.4 1.9 0.2 Iris setosa ## 26 5.0 3.0 1.6 0.2 Iris setosa ## 27 5.0 3.4 1.6 0.4 Iris setosa ## 28 5.2 3.5 1.5 0.2 Iris setosa ## 29 5.2 3.4 1.4 0.2 Iris setosa ## 30 4.7 3.2 1.6 0.2 Iris setosa ## 31 4.8 3.1 1.6 0.2 Iris setosa ## 32 5.4 3.4 1.5 0.4 Iris setosa ## 33 5.2 4.1 1.5 0.1 Iris setosa ## 34 5.5 4.2 1.4 0.2 Iris setosa ## 35 4.9 3.1 1.5 0.2 Iris setosa ## 36 5.0 3.2 1.2 0.2 Iris setosa ## 37 5.5 3.5 1.3 0.2 Iris setosa ## 38 4.9 3.6 1.4 0.1 Iris setosa ## 39 4.4 3.0 1.3 0.2 Iris setosa ## 40 5.1 3.4 1.5 0.2 Iris setosa ## 41 5.0 3.5 1.3 0.3 Iris setosa ## 42 4.5 2.3 1.3 0.3 Iris setosa ## 43 4.4 3.2 1.3 0.2 Iris setosa ## 44 5.0 3.5 1.6 0.6 Iris setosa ## 45 5.1 3.8 1.9 0.4 Iris setosa ## 46 4.8 3.0 1.4 0.3 Iris setosa ## 47 5.1 3.8 1.6 0.2 Iris setosa ## 48 4.6 3.2 1.4 0.2 Iris setosa ## 49 5.3 3.7 1.5 0.2 Iris setosa ## 50 5.0 3.3 1.4 0.2 Iris setosa ## 51 7.0 3.2 4.7 1.4 Iris versicolor ## 52 6.4 3.2 4.5 1.5 Iris versicolor ## 53 6.9 3.1 4.9 1.5 Iris versicolor ## 54 5.5 2.3 4.0 1.3 Iris versicolor ## 55 6.5 2.8 4.6 1.5 Iris versicolor ## 56 5.7 2.8 4.5 1.3 Iris versicolor ## 57 6.3 3.3 4.7 1.6 Iris versicolor ## 58 4.9 2.4 3.3 1.0 Iris versicolor ## 59 6.6 2.9 4.6 1.3 Iris versicolor ## 60 5.2 2.7 3.9 1.4 Iris versicolor ## 61 5.0 2.0 3.5 1.0 Iris versicolor ## 62 5.9 3.0 4.2 1.5 Iris versicolor ## 63 6.0 2.2 4.0 1.0 Iris versicolor ## 64 6.1 2.9 4.7 1.4 Iris versicolor ## 65 5.6 2.9 3.6 1.3 Iris versicolor ## 66 6.7 3.1 4.4 1.4 Iris versicolor ## 67 5.6 3.0 4.5 1.5 Iris versicolor ## 68 5.8 2.7 4.1 1.0 Iris versicolor ## 69 6.2 2.2 4.5 1.5 Iris versicolor ## 70 5.6 2.5 3.9 1.1 Iris versicolor ## 71 5.9 3.2 4.8 1.8 Iris versicolor ## 72 6.1 2.8 4.0 1.3 Iris versicolor ## 73 6.3 2.5 4.9 1.5 Iris versicolor ## 74 6.1 2.8 4.7 1.2 Iris versicolor ## 75 6.4 2.9 4.3 1.3 Iris versicolor ## 76 6.6 3.0 4.4 1.4 Iris versicolor ## 77 6.8 2.8 4.8 1.4 Iris versicolor ## 78 6.7 3.0 5.0 1.7 Iris versicolor ## 79 6.0 2.9 4.5 1.5 Iris versicolor ## 80 5.7 2.6 3.5 1.0 Iris versicolor ## 81 5.5 2.4 3.8 1.1 Iris versicolor ## 82 5.5 2.4 3.7 1.0 Iris versicolor ## 83 5.8 2.7 3.9 1.2 Iris versicolor ## 84 6.0 2.7 5.1 1.6 Iris versicolor ## 85 5.4 3.0 4.5 1.5 Iris versicolor ## 86 6.0 3.4 4.5 1.6 Iris versicolor ## 87 6.7 3.1 4.7 1.5 Iris versicolor ## 88 6.3 2.3 4.4 1.3 Iris versicolor ## 89 5.6 3.0 4.1 1.3 Iris versicolor ## 90 5.5 2.5 4.0 1.3 Iris versicolor ## 91 5.5 2.6 4.4 1.2 Iris versicolor ## 92 6.1 3.0 4.6 1.4 Iris versicolor ## 93 5.8 2.6 4.0 1.2 Iris versicolor ## 94 5.0 2.3 3.3 1.0 Iris versicolor ## 95 5.6 2.7 4.2 1.3 Iris versicolor ## 96 5.7 3.0 4.2 1.2 Iris versicolor ## 97 5.7 2.9 4.2 1.3 Iris versicolor ## 98 6.2 2.9 4.3 1.3 Iris versicolor ## 99 5.1 2.5 3.0 1.1 Iris versicolor ## 100 5.7 2.8 4.1 1.3 Iris versicolor ## 101 6.3 3.3 6.0 2.5 Iris virginica ## 102 5.8 2.7 5.1 1.9 Iris virginica ## 103 7.1 3.0 5.9 2.1 Iris virginica ## 104 6.3 2.9 5.6 1.8 Iris virginica ## 105 6.5 3.0 5.8 2.2 Iris virginica ## 106 7.6 3.0 6.6 2.1 Iris virginica ## 107 4.9 2.5 4.5 1.7 Iris virginica ## 108 7.3 2.9 6.3 1.8 Iris virginica ## 109 6.7 2.5 5.8 1.8 Iris virginica ## 110 7.2 3.6 6.1 2.5 Iris virginica ## 111 6.5 3.2 5.1 2.0 Iris virginica ## 112 6.4 2.7 5.3 1.9 Iris virginica ## 113 6.8 3.0 5.5 2.1 Iris virginica ## 114 5.7 2.5 5.0 2.0 Iris virginica ## 115 5.8 2.8 5.1 2.4 Iris virginica ## 116 6.4 3.2 5.3 2.3 Iris virginica ## 117 6.5 3.0 5.5 1.8 Iris virginica ## 118 7.7 3.8 6.7 2.2 Iris virginica ## 119 7.7 2.6 6.9 2.3 Iris virginica ## 120 6.0 2.2 5.0 1.5 Iris virginica ## 121 6.9 3.2 5.7 2.3 Iris virginica ## 122 5.6 2.8 4.9 2.0 Iris virginica ## 123 7.7 2.8 6.7 2.0 Iris virginica ## 124 6.3 2.7 4.9 1.8 Iris virginica ## 125 6.7 3.3 5.7 2.1 Iris virginica ## 126 7.2 3.2 6.0 1.8 Iris virginica ## 127 6.2 2.8 4.8 1.8 Iris virginica ## 128 6.1 3.0 4.9 1.8 Iris virginica ## 129 6.4 2.8 5.6 2.1 Iris virginica ## 130 7.2 3.0 5.8 1.6 Iris virginica ## 131 7.4 2.8 6.1 1.9 Iris virginica ## 132 7.9 3.8 6.4 2.0 Iris virginica ## 133 6.4 2.8 5.6 2.2 Iris virginica ## 134 6.3 2.8 5.1 1.5 Iris virginica ## 135 6.1 2.6 5.6 1.4 Iris virginica ## 136 7.7 3.0 6.1 2.3 Iris virginica ## 137 6.3 3.4 5.6 2.4 Iris virginica ## 138 6.4 3.1 5.5 1.8 Iris virginica ## 139 6.0 3.0 4.8 1.8 Iris virginica ## 140 6.9 3.1 5.4 2.1 Iris virginica ## 141 6.7 3.1 5.6 2.4 Iris virginica ## 142 6.9 3.1 5.1 2.3 Iris virginica ## 143 5.8 2.7 5.1 1.9 Iris virginica ## 144 6.8 3.2 5.9 2.3 Iris virginica ## 145 6.7 3.3 5.7 2.5 Iris virginica ## 146 6.7 3.0 5.2 2.3 Iris virginica ## 147 6.3 2.5 5.0 1.9 Iris virginica ## 148 6.5 3.0 5.2 2.0 Iris virginica ## 149 6.2 3.4 5.4 2.3 Iris virginica ## 150 5.9 3.0 5.1 1.8 Iris virginica ## size_sepal_length ## 1 medium ## 2 small ## 3 small ## 4 small ## 5 medium ## 6 medium ## 7 small ## 8 medium ## 9 small ## 10 small ## 11 medium ## 12 small ## 13 small ## 14 small ## 15 medium ## 16 medium ## 17 medium ## 18 medium ## 19 medium ## 20 medium ## 21 medium ## 22 medium ## 23 small ## 24 medium ## 25 small ## 26 medium ## 27 medium ## 28 medium ## 29 medium ## 30 small ## 31 small ## 32 medium ## 33 medium ## 34 medium ## 35 small ## 36 medium ## 37 medium ## 38 small ## 39 small ## 40 medium ## 41 medium ## 42 small ## 43 small ## 44 medium ## 45 medium ## 46 small ## 47 medium ## 48 small ## 49 medium ## 50 medium ## 51 large ## 52 medium ## 53 medium ## 54 medium ## 55 medium ## 56 medium ## 57 medium ## 58 small ## 59 medium ## 60 medium ## 61 medium ## 62 medium ## 63 medium ## 64 medium ## 65 medium ## 66 medium ## 67 medium ## 68 medium ## 69 medium ## 70 medium ## 71 medium ## 72 medium ## 73 medium ## 74 medium ## 75 medium ## 76 medium ## 77 medium ## 78 medium ## 79 medium ## 80 medium ## 81 medium ## 82 medium ## 83 medium ## 84 medium ## 85 medium ## 86 medium ## 87 medium ## 88 medium ## 89 medium ## 90 medium ## 91 medium ## 92 medium ## 93 medium ## 94 medium ## 95 medium ## 96 medium ## 97 medium ## 98 medium ## 99 medium ## 100 medium ## 101 medium ## 102 medium ## 103 large ## 104 medium ## 105 medium ## 106 large ## 107 small ## 108 large ## 109 medium ## 110 large ## 111 medium ## 112 medium ## 113 medium ## 114 medium ## 115 medium ## 116 medium ## 117 medium ## 118 large ## 119 large ## 120 medium ## 121 medium ## 122 medium ## 123 large ## 124 medium ## 125 medium ## 126 large ## 127 medium ## 128 medium ## 129 medium ## 130 large ## 131 large ## 132 large ## 133 medium ## 134 medium ## 135 medium ## 136 large ## 137 medium ## 138 medium ## 139 medium ## 140 medium ## 141 medium ## 142 medium ## 143 medium ## 144 medium ## 145 medium ## 146 medium ## 147 medium ## 148 medium ## 149 medium ## 150 medium "],
["for-loops.html", "4 For loops 4.1 What is a for loop? 4.2 A brief detour into indexing 4.3 C", " 4 For loops For loops can be a bit of a contentious issue in the R community. If you search for “for loops R” on Google, you’ll find plenty of examples on how to use them and just as many people arguing that they should be avoided. I won’t be delving into this argument much in this document other than to say that for loops can be powerful tools for manipulating data in an intuitive way, especially for people who are new to programming. The downside to for loops is that they can be slow compared to other R programming alternatives, depending on how you implement them and the problem you’re trying to solve. Slow in computer programming is a relative term though and really depends on the size of the data you are working with. If you are working with millions of rows of data or thousands of different data sets simultaneously (what I call capital B&amp;D Big Data), you probably will find the time it takes for loops to run prohibitive. If you’re like most of the people I work with though, you might have a lot of data but not capital B&amp;D Big Data. In this case, for loops will probably work just fine. They may not be as fast as other alternatives but because the data you work with is so much smaller, the difference in running time becomes negligible. One downside to for loops in R is that they can promote really sloppy code. This can definitely affect readability (and therefore reproducibility). Most readability issues related to for loops will occur because for loops can be nested (we’ll cover this later). You should avoid the temptation to nest multiple for loops; instead seek out an alternative method if reproducibility and readability are among your goals. This tutorial will emphasize making your for loops as readable as possible so they can remain a useful tool in your R toolbox. 4.1 What is a for loop? A for loop is a programming concept which allows us to “loop” or move through our data in a specific way and as we move through our data, perform an operation on each part of the data. For loops can be used for a multitude of objectives but are really useful when you need to derive variables that rely on the value of a variable that came previously (like figuring out the turn angle between two successive movements by an insect) or for splitting your data and doing something specific with it (like producing maps of what counties different species of buprestid beetles have been caught in). Let’s see a basic example to illustrate how a for loop works. ## [1] 2 ## [1] 4 ## [1] 6 ## [1] 8 ## [1] 10 ## [1] 12 ## [1] 14 ## [1] 16 ## [1] 18 ## [1] 20 If you’re familiar with R, you probably understand that by using the : operator, we told R to generate a vector of all the whole numbers between 1 and 10 and stored those numbers in the object numbers. How do we read the for loop though and decipher what happened? First, let’s note that for is a special type of construct in R, it’s not a function (i.e. it doesn’t take input and produce output like mean() does). The for is used to control the flow of code. There are other flow control constructs, like if/else, while, repeat that we may cover later, but for now we’re going to focus on for. So, how does for control the flow of our code? To figure out what for needs to do, it’s going to look inside the parentheses that follow the for command. In our code, this was (i in numbers). Putting it all together for (i in numbers), can be read as “for every object/piece/component ‘i’ in the object ‘numbers’, do something”. In the for instructions, “i” is an index. That just means that “i” will at some point take on every value contained in our object numbers, and we can see that if we look at the code that follows the for (i in numbers) piece. After our closed parenthesis there are a pair of curly brackets {} with code in between them. The curly braces are used to tell R that the code between them should all be run together as part of one loop. In our example, we only have one line of code but you can put many lines of code into the curly braces of a for loop. Inside our curly braces we have the code print(i * 2). The print() function, for those that haven’t seen it, just tells R to “print” whatever is inside the function to the console. It’s a way to have output returned to you immediately to see what happened. Inside print(), we’re multiplying our index i by 2. Once the multiplication is complete, the result is returned to the console by print(). R knows what values to assign to i because we told it to before the curly brackets. So, R is assigning the first value from our numbers object, which is 1, to the object i. Then, R is multiplying i times 2 and printing the result. Once R has printed our result, it goes back to the start of the for loop and basically asks “are there any more values i needs to become?”. If R hasn’t looped through all the values stored in numbers then it will go on to the next value and repeat the process of multiplying i by 2 and printing the result. Once it’s reached the last value stored in numbers, R stops running the for loop and would move on to any code outside the curly brackets, if there were any. Putting it all together, we tell R to move through all the numbers 1 through 10, multiply them by 2 one at a time, and then print the result. It’s a highly contrived example (and you’d never want to actually use a for loop to do this. Instead just type numbers * 2) but it serves to illustrate how the for loop works. 4.2 A brief detour into indexing Before we can move onto more complex applications of the for loop, we need to lay a little foundation around the idea of indexing. Indexing is a tool that allows you to pull out specific subsets of an object based on their location or name. Indexing is done by placing square brackets [] after the object you want to index. For example, we can use indexing to pull out row 10 of the iris dataset. iris[10, ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 10 4.9 3.1 1.5 0.1 setosa We can specify that we want a specific column from row 10 by adding the position of the column or the name of the column after the comma in the []. Let’s look at the Sepal.Width for the iris in row 10. iris[10, 2] ## [1] 3.1 iris[10, &quot;Sepal.Width&quot;] ## [1] 3.1 Both methods return the value for Sepal.Width in row 10. You can use the : operator or c() to specify a range or selection of rows and columns as well. iris[10:20, c(&quot;Sepal.Length&quot;, &quot;Petal.Length&quot;)] ## Sepal.Length Petal.Length ## 10 4.9 1.5 ## 11 5.4 1.5 ## 12 4.8 1.6 ## 13 4.8 1.4 ## 14 4.3 1.1 ## 15 5.8 1.2 ## 16 5.7 1.5 ## 17 5.4 1.3 ## 18 5.1 1.4 ## 19 5.7 1.7 ## 20 5.1 1.5 You can also specify a vector of positions or column names, assign that vector to an object and then reference that object when indexing. Let’s say we want to look at just the columns in the iris dataset associated with length. length.columns &lt;- c(&quot;Sepal.Length&quot;, &quot;Petal.Length&quot;) iris[, length.columns] ## Sepal.Length Petal.Length ## 1 5.1 1.4 ## 2 4.9 1.4 ## 3 4.7 1.3 ## 4 4.6 1.5 ## 5 5.0 1.4 ## 6 5.4 1.7 ## 7 4.6 1.4 ## 8 5.0 1.5 ## 9 4.4 1.4 ## 10 4.9 1.5 ## 11 5.4 1.5 ## 12 4.8 1.6 ## 13 4.8 1.4 ## 14 4.3 1.1 ## 15 5.8 1.2 ## 16 5.7 1.5 ## 17 5.4 1.3 ## 18 5.1 1.4 ## 19 5.7 1.7 ## 20 5.1 1.5 ## 21 5.4 1.7 ## 22 5.1 1.5 ## 23 4.6 1.0 ## 24 5.1 1.7 ## 25 4.8 1.9 ## 26 5.0 1.6 ## 27 5.0 1.6 ## 28 5.2 1.5 ## 29 5.2 1.4 ## 30 4.7 1.6 ## 31 4.8 1.6 ## 32 5.4 1.5 ## 33 5.2 1.5 ## 34 5.5 1.4 ## 35 4.9 1.5 ## 36 5.0 1.2 ## 37 5.5 1.3 ## 38 4.9 1.4 ## 39 4.4 1.3 ## 40 5.1 1.5 ## 41 5.0 1.3 ## 42 4.5 1.3 ## 43 4.4 1.3 ## 44 5.0 1.6 ## 45 5.1 1.9 ## 46 4.8 1.4 ## 47 5.1 1.6 ## 48 4.6 1.4 ## 49 5.3 1.5 ## 50 5.0 1.4 ## 51 7.0 4.7 ## 52 6.4 4.5 ## 53 6.9 4.9 ## 54 5.5 4.0 ## 55 6.5 4.6 ## 56 5.7 4.5 ## 57 6.3 4.7 ## 58 4.9 3.3 ## 59 6.6 4.6 ## 60 5.2 3.9 ## 61 5.0 3.5 ## 62 5.9 4.2 ## 63 6.0 4.0 ## 64 6.1 4.7 ## 65 5.6 3.6 ## 66 6.7 4.4 ## 67 5.6 4.5 ## 68 5.8 4.1 ## 69 6.2 4.5 ## 70 5.6 3.9 ## 71 5.9 4.8 ## 72 6.1 4.0 ## 73 6.3 4.9 ## 74 6.1 4.7 ## 75 6.4 4.3 ## 76 6.6 4.4 ## 77 6.8 4.8 ## 78 6.7 5.0 ## 79 6.0 4.5 ## 80 5.7 3.5 ## 81 5.5 3.8 ## 82 5.5 3.7 ## 83 5.8 3.9 ## 84 6.0 5.1 ## 85 5.4 4.5 ## 86 6.0 4.5 ## 87 6.7 4.7 ## 88 6.3 4.4 ## 89 5.6 4.1 ## 90 5.5 4.0 ## 91 5.5 4.4 ## 92 6.1 4.6 ## 93 5.8 4.0 ## 94 5.0 3.3 ## 95 5.6 4.2 ## 96 5.7 4.2 ## 97 5.7 4.2 ## 98 6.2 4.3 ## 99 5.1 3.0 ## 100 5.7 4.1 ## 101 6.3 6.0 ## 102 5.8 5.1 ## 103 7.1 5.9 ## 104 6.3 5.6 ## 105 6.5 5.8 ## 106 7.6 6.6 ## 107 4.9 4.5 ## 108 7.3 6.3 ## 109 6.7 5.8 ## 110 7.2 6.1 ## 111 6.5 5.1 ## 112 6.4 5.3 ## 113 6.8 5.5 ## 114 5.7 5.0 ## 115 5.8 5.1 ## 116 6.4 5.3 ## 117 6.5 5.5 ## 118 7.7 6.7 ## 119 7.7 6.9 ## 120 6.0 5.0 ## 121 6.9 5.7 ## 122 5.6 4.9 ## 123 7.7 6.7 ## 124 6.3 4.9 ## 125 6.7 5.7 ## 126 7.2 6.0 ## 127 6.2 4.8 ## 128 6.1 4.9 ## 129 6.4 5.6 ## 130 7.2 5.8 ## 131 7.4 6.1 ## 132 7.9 6.4 ## 133 6.4 5.6 ## 134 6.3 5.1 ## 135 6.1 5.6 ## 136 7.7 6.1 ## 137 6.3 5.6 ## 138 6.4 5.5 ## 139 6.0 4.8 ## 140 6.9 5.4 ## 141 6.7 5.6 ## 142 6.9 5.1 ## 143 5.8 5.1 ## 144 6.8 5.9 ## 145 6.7 5.7 ## 146 6.7 5.2 ## 147 6.3 5.0 ## 148 6.5 5.2 ## 149 6.2 5.4 ## 150 5.9 5.1 By leaving the row portion of the index blank, we returned all rows. R then checked the length.columns object to see what was stored there, so it knew to return Sepal.Length and Petal.Length. Being able to use variables inside indexing will allow us to access more of the power available from for loops. 4.3 C "],
["r-markdown.html", "5 R Markdown 5.1 Headers!", " 5 R Markdown This is an R markdown document. R markdown documents are a wonderful tool for weaving text together with code and figures. These documents can be output in a number of formats, like PDF, HTML, word documents, and even slide show presentations. You can type regularly in this document like I am here. There are basic formatting options available like: 5.1 Headers! lists bold italics Equations: \\(4 = x + 2\\) many others! We won’t be going in depth into R markdown in this activity, I just wanted to introduce it because we’ll be using markdown to work through these activities. To learn more about R markdown, google “R markdown cheat sheet” or go to this link. Side note: Because the document we’re working in right now is an html_notebook (see the “output” section at the top of the R markdown document), you can preview what this document will look like as an HTML file by hitting “Preview” up above or pressing ctrl + shift + k. "]
]
